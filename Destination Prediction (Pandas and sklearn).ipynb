{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import geohash\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "import math\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15285988, 5)\n"
     ]
    }
   ],
   "source": [
    "# Each line is of the format:\n",
    "\n",
    "#pickupGeohash, dropOffGeohash,time_num,day_of_week, count\n",
    "\n",
    "names = [\"pickup_geohash\",\"dropoff_geohash\",\"time_num\",\"day_of_week\", \"count\"]\n",
    "df=pd.read_csv(\"./tmplocaldata/final/singlefile/part-00000\", header=None, names = names)\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the longitude and latitude from the geohash\n",
    "def decodegeo(geo, which):\n",
    "    if len(geo) >= 6:\n",
    "        geodecoded = geohash.decode(geo)\n",
    "        return geodecoded[which]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def further_data_prep(df):\n",
    "  \n",
    "    df['time_sin'] = (df['time_num'] * 2 * math.pi).apply(math.sin)\n",
    "    df['time_cos'] = (df['time_num'] * 2 * math.pi).apply(math.cos)\n",
    "    df['pickup_lat'] = df['pickup_geohash'].apply(lambda geo: decodegeo(geo, 0))\n",
    "    df['pickup_long'] = df['pickup_geohash'].apply(lambda geo: decodegeo(geo, 1))\n",
    "    df['dropoff_lat'] = df['dropoff_geohash'].apply(lambda geo: decodegeo(geo, 0))\n",
    "    df['dropoff_long'] = df['dropoff_geohash'].apply(lambda geo: decodegeo(geo, 1))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = further_data_prep(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_df = df[['time_num', 'time_sin', 'time_cos','day_of_week', 'pickup_lat', 'pickup_long', 'count']]\n",
    "target_df = df[['dropoff_lat', 'dropoff_long']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( features_df, target_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DevLibs\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\DevLibs\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "pickup_count_train = X_train[['count']]\n",
    "X_train.drop('count', axis=1, inplace=True)\n",
    "\n",
    "pickup_count_test = X_test[['count']]\n",
    "X_test.drop('count', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning (without using sample weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of  20 | elapsed:  2.5min remaining: 47.8min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  20 | elapsed:  2.5min remaining: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  20 | elapsed:  5.3min remaining:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:  5.6min remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
       "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=20, n_jobs=-1, oob_score=False, random_state=None,\n",
       "           verbose=4, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = RandomForestRegressor(n_estimators=20, max_depth=20, n_jobs=-1, verbose=4)\n",
    "reg.fit(X_train,y_train) #, pickup_count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   1 out of  20 | elapsed:    6.2s remaining:  2.0min\n",
      "[Parallel(n_jobs=8)]: Done   4 out of  20 | elapsed:    7.0s remaining:   28.3s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  20 | elapsed:   11.1s remaining:   11.1s\n",
      "[Parallel(n_jobs=8)]: Done  16 out of  20 | elapsed:   12.8s remaining:    3.1s\n",
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed:   16.5s finished\n",
      "[Parallel(n_jobs=8)]: Done   4 out of  20 | elapsed:    1.2s remaining:    5.0s\n",
      "[Parallel(n_jobs=8)]: Done   1 out of  20 | elapsed:    1.3s remaining:   26.7s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  20 | elapsed:    2.6s remaining:    2.6s\n",
      "[Parallel(n_jobs=8)]: Done  16 out of  20 | elapsed:    3.0s remaining:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=8)]: Done   1 out of  20 | elapsed:    5.7s remaining:  1.8min\n",
      "[Parallel(n_jobs=8)]: Done   4 out of  20 | elapsed:    6.6s remaining:   26.7s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  20 | elapsed:   11.0s remaining:   11.0s\n",
      "[Parallel(n_jobs=8)]: Done  16 out of  20 | elapsed:   12.4s remaining:    3.0s\n",
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed:   16.1s finished\n",
      "[Parallel(n_jobs=8)]: Done   4 out of  20 | elapsed:    1.4s remaining:    5.7s\n",
      "[Parallel(n_jobs=8)]: Done   1 out of  20 | elapsed:    1.6s remaining:   31.5s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  20 | elapsed:    2.8s remaining:    2.8s\n",
      "[Parallel(n_jobs=8)]: Done  16 out of  20 | elapsed:    3.0s remaining:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " R^2 (train) = 0.254, R^2 (valid) = 0.141, RMSE (train) = 0.105, RMSE (valid) = 0.115\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = reg.score(X_train, y_train)\n",
    "valid_accuracy = reg.score(X_test, y_test)\n",
    "rmsetrain = np.sqrt(mean_squared_error(reg.predict(X_train),y_train))\n",
    "rmsevalid = np.sqrt(mean_squared_error(reg.predict(X_test),y_test))\n",
    "print \" R^2 (train) = %0.3f, R^2 (valid) = %0.3f, RMSE (train) = %0.3f, RMSE (valid) = %0.3f\" % (training_accuracy, valid_accuracy, rmsetrain, rmsevalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning (with using sample weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not working\n",
    "reg1 = RandomForestRegressor(n_estimators=10, max_depth=10, n_jobs=-1)\n",
    "reg1.fit(X_train,y_train , sample_weight = pickup_count_train.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
